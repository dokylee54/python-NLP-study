{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost = 158.703898744\n",
      "Epoch: 0002 Cost = 38.958855700\n",
      "Epoch: 0003 Cost = 23.941824499\n",
      "Epoch: 0004 Cost = 16.649136921\n",
      "Epoch: 0005 Cost = 12.083894674\n",
      "Epoch: 0006 Cost = 8.895873140\n",
      "Epoch: 0007 Cost = 6.720665525\n",
      "Epoch: 0008 Cost = 4.939698422\n",
      "Epoch: 0009 Cost = 3.765803841\n",
      "Epoch: 0010 Cost = 2.865051300\n",
      "Epoch: 0011 Cost = 2.197929080\n",
      "Epoch: 0012 Cost = 1.622566787\n",
      "Epoch: 0013 Cost = 1.199940983\n",
      "Epoch: 0014 Cost = 0.950252560\n",
      "Epoch: 0015 Cost = 0.727803949\n",
      "Learning finished!\n",
      "Accuracy: 0.9426\n",
      "Label: [5]\n",
      "Prediction: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAANiElEQVR4nO3db4hd9Z3H8c/HmMZgiyYzQwg2mG4RVBY3LUNcbCjZyFYTxFgRScCaBN1pQKGBIivug/hAIVm3rX2wBFITOl26iYEqEZFuNRZDQYuTmHWig2tWxvwhJhN9UAtqNsl3H8xJmcS5507uPfdP5/t+weXee773zPlyyCfn3vM79/4cEQIw/V3W6QYAtAdhB5Ig7EAShB1IgrADSVzezo319vbGwoUL27lJIJXR0VGdOnXKk9WaCrvt2yX9XNIMSc9ExKay1y9cuFBDQ0PNbBJAif7+/pq1ht/G254h6d8lLZd0o6TVtm9s9O8BaK1mPrMvlnQoIj6IiNOSdkpaWU1bAKrWTNivkXRkwvOjxbIL2B6wPWR7aGxsrInNAWhGy8/GR8TWiOiPiP6+vr5Wbw5ADc2E/ZikBROef71YBqALNRP2NyVdZ/sbtr8iaZWkF6ppC0DVGh56i4gzth+W9F8aH3rbHhHvVNYZgEo1Nc4eES9JeqmiXgC0EJfLAkkQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kERTs7iiO+zdu7dm7ZVXXmljJ5dmcHCwtH748OHS+rp160rr27dvv+SeprOmwm57VNKnks5KOhMR/VU0BaB6VRzZ/yEiTlXwdwC0EJ/ZgSSaDXtI+p3tfbYHJnuB7QHbQ7aHxsbGmtwcgEY1G/YlEfFtScslPWT7uxe/ICK2RkR/RPT39fU1uTkAjWoq7BFxrLg/Kel5SYuraApA9RoOu+0rbX/t/GNJ35N0sKrGAFSrmbPx8yQ9b/v83/nPiPhtJV3hkmzZsqVmbdeuXW3spFp33313aX3z5s1t6mR6aDjsEfGBpL+rsBcALcTQG5AEYQeSIOxAEoQdSIKwA0nwFddpYPHi2tcy1Rt6e/XVV0vrt9xyS0M9VeGyy8qPRTNmzGhTJ9MDR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9mmg7Cuu9dxwww2l9ZkzZzb8t9FdOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs09zs2bNKq3znfA8OLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs09zy5cvL6339PS0qRN0Wt0ju+3ttk/aPjhh2VzbL9t+v7if09o2ATRrKm/jfynp9ouWPSppT0RcJ2lP8RxAF6sb9ojYK+mTixavlDRYPB6UdFfFfQGoWKMn6OZFxPHi8UeS5tV6oe0B20O2h8bGxhrcHIBmNX02PiJCUpTUt0ZEf0T09/X1Nbs5AA1qNOwnbM+XpOL+ZHUtAWiFRsP+gqQ1xeM1knZX0w6AVqk7zm57h6SlknptH5W0UdImSbtsPyDpQ0n3trLJ7IaHh0vro6OjNWtPPvlk6bqfffZZaf3ZZ58trdfT29tbs7ZixYrSdevNz45LUzfsEbG6RunWinsB0EL81wkkQdiBJAg7kARhB5Ig7EASfMW1C9Qb/rrzzjtL62fPnq1ZW7VqVUM9tcM999xTWq83FfXcuXOrbGfa48gOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzt4FDh06VFo/fPhww3+73pTMS5YsKa2vXl3rS4/jbrrpptL6yMhIzdqDDz5Yuu78+fNL608//XRpHRfiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gVee+21ptZftmxZzdquXbtK150zp7UT8N588801a6+//nrpuoODg6X19evXl9avv/760no2HNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2btAve+MHz16tLS+cePGmrXZs2c31FM73HfffaX1Z555prT+1FNPlda3bdt2yT1NZ3WP7La32z5p++CEZY/bPmb7QHErn2gbQMdN5W38LyXdPsnyn0XEouL2UrVtAaha3bBHxF5Jn7ShFwAt1MwJuodtv128za95gbXtAdtDtofGxsaa2ByAZjQa9i2SvilpkaTjkn5S64URsTUi+iOiv6+vr8HNAWhWQ2GPiBMRcTYizkn6haTF1bYFoGoNhd32xN/4/b6kg7VeC6A71B1nt71D0lJJvbaPStooaantRZJC0qikH7awx2mvp6entL5p06Y2ddJe9X6z/uqrry6t1/s+/Oeff16zdsUVV5SuOx3VDXtETHbFB1crAH9luFwWSIKwA0kQdiAJwg4kQdiBJPiKKzrGdml97dq1pfV6U11ffjn/vCfiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTAQmdwXX3xRWp81a1abOvmyHTt2lNaXL19eWmec/UIc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCQYip7n9+/eX1vfu3Vta37BhQ5XtXOC9994rrX/88cct23ZGHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2aeB5557rmbt/vvvL113ZGSk6nambPfu3aX1M2fOlNZnz55dZTvTXt0ju+0Ftn9v+13b79j+UbF8ru2Xbb9f3M9pfbsAGjWVt/FnJP04Im6U9PeSHrJ9o6RHJe2JiOsk7SmeA+hSdcMeEccjYn/x+FNJI5KukbRS0mDxskFJd7WqSQDNu6QTdLYXSvqWpD9KmhcRx4vSR5Lm1VhnwPaQ7aGxsbEmWgXQjCmH3fZXJf1G0oaI+NPEWkSEpJhsvYjYGhH9EdHf19fXVLMAGjelsNueqfGg/zoizp/6PWF7flGfL+lka1oEUIW6Q28en1d3m6SRiPjphNILktZI2lTcl4+joGWGh4dr1np7e0vXnTOntYMop0+frlmrN/RWb2jtkUceaainrKYyzv4dST+QNGz7QLHsMY2HfJftByR9KOne1rQIoAp1wx4Rf5DkGuVbq20HQKtwuSyQBGEHkiDsQBKEHUiCsANJ8BXXaaBsLP3IkSOl6+7bt6+0vmTJktL6uXPnSusDAwM1a2+88UbpumvXri2tX3vttaV1XIgjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTj7NLB+/fqatRdffLF03WXLlpXWb7vtttJ6vSmhy36KbN26daXrPvHEE6V1XBqO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPs08CMGTNq1nbu3Fm67ltvvVVav/XW5n5A+I477qhZ27x5c+m6PT09TW0bF+LIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJTGV+9gWSfiVpnqSQtDUifm77cUn/JOn8F5Yfi4iXWtUoGnPVVVeV1pcuXVpaP3v2bIXdoJOmclHNGUk/joj9tr8maZ/tl4vazyLi31rXHoCqTGV+9uOSjhePP7U9IumaVjcGoFqX9Jnd9kJJ35L0x2LRw7bftr3d9pwa6wzYHrI9VPYTRQBaa8pht/1VSb+RtCEi/iRpi6RvSlqk8SP/TyZbLyK2RkR/RPT39fVV0DKARkwp7LZnajzov46I5yQpIk5ExNmIOCfpF5IWt65NAM2qG3bblrRN0khE/HTC8vkTXvZ9SQerbw9AVaZyNv47kn4gadj2gWLZY5JW216k8eG4UUk/bEmHACoxlbPxf5DkSUqMqQN/RbiCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kIQjon0bs8ckfThhUa+kU21r4NJ0a2/d2pdEb42qsrdrI2LS339ra9i/tHF7KCL6O9ZAiW7trVv7kuitUe3qjbfxQBKEHUii02Hf2uHtl+nW3rq1L4neGtWW3jr6mR1A+3T6yA6gTQg7kERHwm77dtvv2T5k+9FO9FCL7VHbw7YP2B7qcC/bbZ+0fXDCsrm2X7b9fnE/6Rx7HertcdvHin13wPaKDvW2wPbvbb9r+x3bPyqWd3TflfTVlv3W9s/stmdI+h9J/yjpqKQ3Ja2OiHfb2kgNtkcl9UdExy/AsP1dSX+W9KuI+Nti2b9K+iQiNhX/Uc6JiH/ukt4el/TnTk/jXcxWNH/iNOOS7pK0Vh3cdyV93as27LdOHNkXSzoUER9ExGlJOyWt7EAfXS8i9kr65KLFKyUNFo8HNf6Ppe1q9NYVIuJ4ROwvHn8q6fw04x3ddyV9tUUnwn6NpCMTnh9Vd833HpJ+Z3uf7YFONzOJeRFxvHj8kaR5nWxmEnWn8W6ni6YZ75p918j0583iBN2XLYmIb0taLumh4u1qV4rxz2DdNHY6pWm822WSacb/opP7rtHpz5vVibAfk7RgwvOvF8u6QkQcK+5PSnpe3TcV9YnzM+gW9yc73M9fdNM03pNNM64u2HednP68E2F/U9J1tr9h+yuSVkl6oQN9fIntK4sTJ7J9paTvqfumon5B0pri8RpJuzvYywW6ZRrvWtOMq8P7ruPTn0dE22+SVmj8jPz/SvqXTvRQo6+/kfTfxe2dTvcmaYfG39b9n8bPbTwgqUfSHknvS3pF0twu6u0/JA1LelvjwZrfod6WaPwt+tuSDhS3FZ3edyV9tWW/cbkskAQn6IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgif8HuMf+n6JSQZAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# NN model\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# training\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning finished!')\n",
    "\n",
    "# test accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "\n",
    "# show the image\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Epoch: 0001 Cost = 0.318791488\n",
      "Epoch: 0002 Cost = 0.119250719\n",
      "Epoch: 0003 Cost = 0.076968447\n",
      "Epoch: 0004 Cost = 0.056476981\n",
      "Epoch: 0005 Cost = 0.041509209\n",
      "Epoch: 0006 Cost = 0.033068594\n",
      "Epoch: 0007 Cost = 0.024980155\n",
      "Epoch: 0008 Cost = 0.020949545\n",
      "Epoch: 0009 Cost = 0.017977988\n",
      "Epoch: 0010 Cost = 0.013776198\n",
      "Epoch: 0011 Cost = 0.011575734\n",
      "Epoch: 0012 Cost = 0.010513941\n",
      "Epoch: 0013 Cost = 0.014248821\n",
      "Epoch: 0014 Cost = 0.010845855\n",
      "Epoch: 0015 Cost = 0.011338351\n",
      "Learning finished!\n",
      "Accuracy: 0.979\n",
      "Label: [2]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# NN model\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# training\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning finished!')\n",
    "\n",
    "# test accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "\n",
    "# show the image\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> normal dist로 했을 때와 비교했을 때, Xavier는 처음부터 cost가 낮음 -> 초기값이 잘 적용되었다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep NN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost = 0.294653674\n",
      "Epoch: 0002 Cost = 0.107485182\n",
      "Epoch: 0003 Cost = 0.072570262\n",
      "Epoch: 0004 Cost = 0.053060758\n",
      "Epoch: 0005 Cost = 0.041414362\n",
      "Epoch: 0006 Cost = 0.036696058\n",
      "Epoch: 0007 Cost = 0.029373592\n",
      "Epoch: 0008 Cost = 0.028983483\n",
      "Epoch: 0009 Cost = 0.023756157\n",
      "Epoch: 0010 Cost = 0.021727809\n",
      "Epoch: 0011 Cost = 0.018766653\n",
      "Epoch: 0012 Cost = 0.016576186\n",
      "Epoch: 0013 Cost = 0.018725824\n",
      "Epoch: 0014 Cost = 0.017664824\n",
      "Epoch: 0015 Cost = 0.012195049\n",
      "Learning finished!\n",
      "Accuracy: 0.9775\n",
      "Label: [0]\n",
      "Prediction: [0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# NN model\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1_1\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2_1\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3_1\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable(\"W4_1\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "W5 = tf.get_variable(\"W5_1\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# training\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning finished!')\n",
    "\n",
    "# test accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "\n",
    "# show the image\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 깊은데 왜 이전보다 낮음? -> Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout for MNIST (Overfit 막기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# NN model\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1_2\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2_2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3_2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4_2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5_2\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# training\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob=0.7}\n",
    "        \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning finished!')\n",
    "\n",
    "# test accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob=1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label:\", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction:\", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r+1], keep_prob=1}))\n",
    "\n",
    "# show the image\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
